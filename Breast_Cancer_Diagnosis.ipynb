{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "from imutils import paths\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')"
      ],
      "metadata": {
        "id": "BZhzTv5R6xaw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the dataset\n",
        "print(\"Downloading dataset...\")\n",
        "path = kagglehub.dataset_download(\"paultimothymooney/breast-histopathology-images\")\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4upk9dTD6zZe",
        "outputId": "8c28ec13-954f-401f-8796-df8ef92b5208"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dataset...\n",
            "Path to dataset files: /kaggle/input/breast-histopathology-images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths\n",
        "input_dataset = path  # Use the downloaded dataset path directly\n",
        "base_path = \"datasets/idc\"\n",
        "train_path = os.path.sep.join([base_path, \"training\"])\n",
        "val_path = os.path.sep.join([base_path, \"validation\"])\n",
        "test_path = os.path.sep.join([base_path, \"testing\"])\n",
        "train_split = 0.8\n",
        "val_split = 0.1"
      ],
      "metadata": {
        "id": "LRKym4fa63Xs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List and shuffle images\n",
        "print(\"Listing images...\")\n",
        "originalPaths = list(paths.list_images(input_dataset))\n",
        "random.seed(7)\n",
        "random.shuffle(originalPaths)\n",
        "print(f\"Found {len(originalPaths)} images\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ru_5xmEy65mn",
        "outputId": "3790caee-04da-4406-865c-0e3fe896d897"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Listing images...\n",
            "Found 555048 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into train, val, test\n",
        "index = int(len(originalPaths) * train_split)\n",
        "trainPaths = originalPaths[:index]\n",
        "testPaths = originalPaths[index:]\n",
        "index = int(len(trainPaths) * val_split)\n",
        "valPaths = trainPaths[:index]\n",
        "trainPaths = trainPaths[index:]\n",
        "print(f\"Train: {len(trainPaths)}, Validation: {len(valPaths)}, Test: {len(testPaths)}\")"
      ],
      "metadata": {
        "id": "3UIOCrDQ67tR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02eaf987-83ff-42c9-8f0c-adafd6f45b31"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 399635, Validation: 44403, Test: 111010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define datasets\n",
        "datasets = [\n",
        "    (\"training\", trainPaths, train_path),\n",
        "    (\"validation\", valPaths, val_path),\n",
        "    (\"testing\", testPaths, test_path)\n",
        "]"
      ],
      "metadata": {
        "id": "I6-ok_JS69MW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Organize files into directories\n",
        "for (setType, originalPaths, basepath) in datasets:\n",
        "    print(f'Building {setType} set')\n",
        "    if not os.path.exists(basepath):\n",
        "        print(f'Building directory {basepath}')\n",
        "        os.makedirs(basepath)\n",
        "    for path in originalPaths:\n",
        "        file = path.split(os.path.sep)[-1]\n",
        "        label = \"0\" if \"class0\" in file else \"1\"  # Extract label from filename\n",
        "        labelPath = os.path.sep.join([basepath, label])\n",
        "        if not os.path.exists(labelPath):\n",
        "            print(f'Building directory {labelPath}')\n",
        "            os.makedirs(labelPath)\n",
        "        newPath = os.path.sep.join([labelPath, file])\n",
        "        shutil.copy2(path, newPath)"
      ],
      "metadata": {
        "id": "DC19Pm8h7Afg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d0f484c-0454-45bf-e50d-7125397a0714"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building training set\n",
            "Building directory datasets/idc/training\n",
            "Building directory datasets/idc/training/0\n",
            "Building directory datasets/idc/training/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the CancerNet model\n",
        "class CancerNet:\n",
        "    @staticmethod\n",
        "    def build(width, height, depth, classes):\n",
        "        model = tf.keras.models.Sequential()\n",
        "        inputShape = (height, width, depth)\n",
        "        channelDim = -1\n",
        "        if tf.keras.backend.image_data_format() == \"channels_first\":\n",
        "            inputShape = (depth, height, width)\n",
        "            channelDim = 1\n",
        "\n",
        "        model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=inputShape))\n",
        "        model.add(tf.keras.layers.BatchNormalization(axis=channelDim))\n",
        "        model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "        model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "        model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
        "        model.add(tf.keras.layers.BatchNormalization(axis=channelDim))\n",
        "        model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
        "        model.add(tf.keras.layers.BatchNormalization(axis=channelDim))\n",
        "        model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "        model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "        model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
        "        model.add(tf.keras.layers.BatchNormalization(axis=channelDim))\n",
        "        model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
        "        model.add(tf.keras.layers.BatchNormalization(axis=channelDim))\n",
        "        model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
        "        model.add(tf.keras.layers.BatchNormalization(axis=channelDim))\n",
        "        model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "        model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "        model.add(tf.keras.layers.Flatten())\n",
        "        model.add(tf.keras.layers.Dense(units=256, activation='relu'))\n",
        "        model.add(tf.keras.layers.BatchNormalization(axis=channelDim))\n",
        "        model.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "        model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))  # Changed to 'sigmoid'\n",
        "        return model\n",
        "\n",
        "# Build the model\n",
        "print(\"Building model...\")\n",
        "model = CancerNet.build(width=64, height=64, depth=3, classes=2)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "NZMpeBa37FbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ScOu8_WTkFUO"
      },
      "outputs": [],
      "source": [
        "# Set up data generator for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "print(\"Loading training data...\")\n",
        "training_set = train_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "# Verify data loading\n",
        "print(\"Class indices:\", training_set.class_indices)\n",
        "\n",
        "# Optional: Train the model (uncomment to run)\n",
        "# print(\"Training model...\")\n",
        "# model.fit(training_set, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1SpSjbKvCWM"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "print(\"Loading validation data...\")\n",
        "# Create an ImageDataGenerator instance for validation data with the same configuration as training data.\n",
        "val_datagen = ImageDataGenerator(rescale=1./255) # Only rescale is needed for validation.\n",
        "validation_set = val_datagen.flow_from_directory(\n",
        "    val_path,\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "\n",
        "# Load test data\n",
        "print(\"Loading test data...\")\n",
        "# For consistency, use the same ImageDataGenerator instance for the test data as well.\n",
        "test_datagen = ImageDataGenerator(rescale=1./255) # Only rescale is needed for test.\n",
        "test_set = test_datagen.flow_from_directory(\n",
        "    test_path,\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    shuffle=False  # Keep order for evaluation\n",
        ")\n",
        "\n",
        "# Verify data loading\n",
        "print(\"Training class indices:\", training_set.class_indices)\n",
        "\n",
        "# Train the model\n",
        "print(\"Training model...\")\n",
        "history = model.fit(\n",
        "    training_set,\n",
        "    epochs=5,\n",
        "    validation_data=validation_set\n",
        ")\n",
        "\n",
        "# Evaluate the model on test set\n",
        "print(\"Evaluating model on test set...\")\n",
        "test_loss, test_accuracy = model.evaluate(test_set)\n",
        "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "# Optional: Save the model\n",
        "model.save(\"cancernet_model.h5\")\n",
        "print(\"Model saved as 'cancernet_model.h5'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3ceW6SNSE84",
        "outputId": "4f747ccc-6372-4858-b7c0-74b3ad7ca8ce"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded successfully.\n",
            "Selected image: datasets/idc/testing/1/9075_idx5_x1301_y351_class1.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338ms/step\n",
            "Image: datasets/idc/testing/1/9075_idx5_x1301_y351_class1.png\n",
            "Prediction: Cancerous (Class 1)\n",
            "Confidence: 0.9079\n",
            "Prediction saved to prediction_result.png\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from imutils import paths\n",
        "\n",
        "# Load the trained model\n",
        "model = tf.keras.models.load_model(\"cancernet_model.h5\")\n",
        "print(\"Model loaded successfully.\")\n",
        "\n",
        "# Function to preprocess a single image\n",
        "def preprocess_image(image_path, target_size=(64, 64)):\n",
        "    img = load_img(image_path, target_size=target_size)\n",
        "    img_array = img_to_array(img) / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    return img_array\n",
        "\n",
        "# Function to predict and display result\n",
        "def predict_breast_cancer(image_path, save_output=False, output_path=\"prediction_output.png\"):\n",
        "    # Preprocess the image\n",
        "    processed_img = preprocess_image(image_path)\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = model.predict(processed_img)[0][0]\n",
        "    label = \"Cancerous (Class 1)\" if prediction >= 0.5 else \"Non-Cancerous (Class 0)\"\n",
        "    confidence = prediction if prediction >= 0.5 else 1 - prediction\n",
        "\n",
        "    # Print result\n",
        "    print(f\"Image: {image_path}\")\n",
        "    print(f\"Prediction: {label}\")\n",
        "    print(f\"Confidence: {confidence:.4f}\")\n",
        "\n",
        "    # Load and display the image\n",
        "    img = load_img(image_path)\n",
        "    plt.figure(figsize=(6, 6))  # Set figure size for better visibility\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"{label} (Confidence: {confidence:.4f})\", fontsize=12)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()  # This displays the image\n",
        "\n",
        "    # Optionally save the output\n",
        "    if save_output:\n",
        "        plt.figure(figsize=(6, 6))  # Recreate figure for saving\n",
        "        plt.imshow(img)\n",
        "        plt.title(f\"{label} (Confidence: {confidence:.4f})\", fontsize=12)\n",
        "        plt.axis(\"off\")\n",
        "        plt.savefig(output_path, bbox_inches='tight', dpi=100)\n",
        "        print(f\"Prediction saved to {output_path}\")\n",
        "        plt.close()  # Close the figure to free memory\n",
        "\n",
        "    return label, confidence\n",
        "\n",
        "# Find an image from the testing set\n",
        "test_images = list(paths.list_images(\"datasets/idc/testing/\"))\n",
        "if not test_images:\n",
        "    print(\"No images found in datasets/idc/testing/. Check your dataset structure.\")\n",
        "    exit()\n",
        "\n",
        "# Use the first available image\n",
        "image_path = test_images[0]  # You can change this index (e.g., test_images[1]) to try different images\n",
        "print(f\"Selected image: {image_path}\")\n",
        "\n",
        "# Predict and display the image\n",
        "if os.path.exists(image_path):\n",
        "    label, confidence = predict_breast_cancer(image_path, save_output=True, output_path=\"prediction_result.png\")\n",
        "else:\n",
        "    print(f\"Image not found at {image_path}. Check the path or dataset.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6D4XWnai2-d"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from imutils import paths\n",
        "\n",
        "# Load the trained model\n",
        "model = tf.keras.models.load_model(\"cancernet_model.h5\")\n",
        "print(\"Model loaded successfully.\")\n",
        "\n",
        "# Function to preprocess a single image\n",
        "def preprocess_image(image_path, target_size=(64, 64)):\n",
        "    img = load_img(image_path, target_size=target_size)\n",
        "    img_array = img_to_array(img) / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    return img_array\n",
        "\n",
        "# Function to predict and display result\n",
        "def predict_breast_cancer(image_path, save_output=False, output_path=\"prediction_output.png\"):\n",
        "    # Preprocess the image\n",
        "    processed_img = preprocess_image(image_path)\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = model.predict(processed_img)[0][0]\n",
        "    label = \"Cancerous (Class 1)\" if prediction >= 0.5 else \"Non-Cancerous (Class 0)\"\n",
        "    confidence = prediction if prediction >= 0.5 else 1 - prediction\n",
        "\n",
        "    # Print result\n",
        "    print(f\"Image: {image_path}\")\n",
        "    print(f\"Prediction: {label}\")\n",
        "    print(f\"Confidence: {confidence:.4f}\")\n",
        "\n",
        "    # Load and display the image\n",
        "    img = load_img(image_path)\n",
        "    plt.figure(figsize=(6, 6))  # Set figure size for better visibility\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"{label} (Confidence: {confidence:.4f})\", fontsize=12)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()  # This displays the image\n",
        "\n",
        "    # Optionally save the output\n",
        "    if save_output:\n",
        "        plt.figure(figsize=(6, 6))  # Recreate figure for saving\n",
        "        plt.imshow(img)\n",
        "        plt.title(f\"{label} (Confidence: {confidence:.4f})\", fontsize=12)\n",
        "        plt.axis(\"off\")\n",
        "        plt.savefig(output_path, bbox_inches='tight', dpi=100)\n",
        "        print(f\"Prediction saved to {output_path}\")\n",
        "        plt.close()  # Close the figure to free memory\n",
        "\n",
        "    return label, confidence\n",
        "\n",
        "# Find an image from the testing set\n",
        "test_images = list(paths.list_images(\"datasets/idc/testing/\"))\n",
        "if not test_images:\n",
        "    print(\"No images found in datasets/idc/testing/. Check your dataset structure.\")\n",
        "    exit()\n",
        "\n",
        "# Use the first available image\n",
        "image_path = test_images[0]  # You can change this index (e.g., test_images[1]) to try different images\n",
        "print(f\"Selected image: {image_path}\")\n",
        "\n",
        "# Predict and display the image\n",
        "if os.path.exists(image_path):\n",
        "    label, confidence = predict_breast_cancer(image_path, save_output=True, output_path=\"prediction_result.png\")\n",
        "else:\n",
        "    print(f\"Image not found at {image_path}. Check the path or dataset.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLwSKW5WSn-Q",
        "outputId": "f919f951-c77f-459f-ab4f-7cb13ee0ba86"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded and recompiled successfully.\n",
            "Found 255813 images belonging to 2 classes.\n",
            "Found 42610 images belonging to 2 classes.\n",
            "Found 99955 images belonging to 2 classes.\n",
            "Training model...\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m7994/7994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4824s\u001b[0m 603ms/step - accuracy: 0.8725 - loss: 0.3054 - val_accuracy: 0.8747 - val_loss: 0.3186\n",
            "Epoch 2/5\n",
            "\u001b[1m   1/7994\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:30:31\u001b[0m 679ms/step - accuracy: 0.8750 - loss: 0.2755"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m7994/7994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 21ms/step - accuracy: 0.8750 - loss: 0.2755 - val_accuracy: 0.8751 - val_loss: 0.3182\n",
            "Epoch 3/5\n",
            "\u001b[1m 687/7994\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:10:40\u001b[0m 580ms/step - accuracy: 0.8780 - loss: 0.2924"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from imutils import paths\n",
        "import os\n",
        "\n",
        "# ... (rest of the code before loading the model) ...\n",
        "\n",
        "# Load the trained model\n",
        "model = load_model(\"cancernet_model.h5\")\n",
        "# Re-compile the model after loading to associate the optimizer with the loaded variables\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "print(\"Model loaded and recompiled successfully.\")\n",
        "\n",
        "# ... (rest of the code) ...\n",
        "\n",
        "# Data generators\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "train_path = \"datasets/idc/training\"\n",
        "training_set = train_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_path = \"datasets/idc/validation\"\n",
        "validation_set = val_datagen.flow_from_directory(\n",
        "    val_path,\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_path = \"datasets/idc/testing\"\n",
        "test_set = test_datagen.flow_from_directory(\n",
        "    test_path,\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    shuffle=False  # Important for aligning predictions with true labels\n",
        ")\n",
        "\n",
        "# Train the model (to get history)\n",
        "print(\"Training model...\")\n",
        "history = model.fit(\n",
        "    training_set,\n",
        "    steps_per_epoch=training_set.samples // training_set.batch_size,\n",
        "    epochs=5,  # Adjust epochs as needed\n",
        "    validation_data=validation_set,\n",
        "    validation_steps=validation_set.samples // validation_set.batch_size,\n",
        "    verbose=1  # Add verbose for progress output\n",
        ")\n",
        "\n",
        "# Plot training history\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss', color='blue')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss', color='orange')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy', color='blue')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='orange')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('training_history.png')  # Save the plot\n",
        "plt.show()\n",
        "\n",
        "# Evaluate the model on test set\n",
        "print(\"Evaluating the model...\")\n",
        "# Use model.predict with the generator\n",
        "predictions = model.predict(test_set, steps=np.ceil(test_set.samples / test_set.batch_size), verbose=1)\n",
        "predicted_labels = (predictions > 0.5).astype(int).flatten()\n",
        "true_labels = test_set.classes[:len(predicted_labels)]  # Match lengths\n",
        "\n",
        "# Compute confusion matrix and classification report\n",
        "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
        "class_report = classification_report(true_labels, predicted_labels, target_names=['Non-Cancerous', 'Cancerous'])\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(class_report)\n",
        "\n",
        "# Custom metrics: Sensitivity, Specificity, Accuracy\n",
        "tn, fp, fn, tp = conf_matrix.ravel()\n",
        "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0  # Recall for Class 1\n",
        "specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "\n",
        "print(\"\\nAdditional Metrics:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Sensitivity: {sensitivity:.4f}\")\n",
        "print(f\"Specificity: {specificity:.4f}\")\n",
        "\n",
        "# Print sensitivity value (as in your example)\n",
        "print(f\"Sensitivity: {sensitivity}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}